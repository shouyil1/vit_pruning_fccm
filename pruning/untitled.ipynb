{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DeiTForImageClassification, DeiTImageProcessor\n",
    "import torch\n",
    "from thop import profile\n",
    "from datasets import load_dataset\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "\n",
    "_, test_ds = load_dataset(\"imagenet-1k\", split=['train', 'validation'])\n",
    "key_to_get_image = 'image'\n",
    "\n",
    "processor = DeiTImageProcessor.from_pretrained(\"/home/dhruv/pruning_vit/pruning/trained-models/deit-small-baseline-imagenet-1k-20240110-014420/best-baseline-loaded-at-end\")\n",
    "\n",
    "image_mean, image_std = processor.image_mean, processor.image_std                 \n",
    "size = processor.crop_size[\"height\"]                                             \n",
    "normalize = Normalize(mean=image_mean, std=image_std)  \n",
    "\n",
    "_val_transforms = Compose(\n",
    "[\n",
    "    Resize(size),\n",
    "    CenterCrop(size),                                             \n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "]\n",
    ")\n",
    "\n",
    "def val_transforms(examples):\n",
    "    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples[key_to_get_image]]\n",
    "    return examples\n",
    "\n",
    "test_ds.set_transform(val_transforms)\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "\n",
    "inputs = collate_fn([test_ds[i] for i in range(1)])\n",
    "print(inputs['pixel_values'].shape)\n",
    "\n",
    "from inference_patchers_blockprune import optimize_model_deit\n",
    "\n",
    "model = optimize_model_deit(DeiTForImageClassification.from_pretrained(pretrained_model_name_or_path=\"trained-models/imagenet-1k_deit_drop_tokens_variant_i_small/epochs_11_blockPruningInfo_finalThreshold_0.5_blockSize_32_method_topK_tokenDropInfo_layerCount_3_layerType_default_keepRate_0.9_fused_True_20231230-020027/fine-pruned-MASKED\"), mode=\"dense\")\n",
    "macs, params = profile(model, inputs=(inputs['pixel_values'],))\n",
    "\n",
    "print(macs/10**9, params/10**6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit_prune_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
